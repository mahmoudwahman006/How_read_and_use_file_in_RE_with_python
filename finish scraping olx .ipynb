{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88faf610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "pagenumber=0\n",
    "link=[]\n",
    "price=[]\n",
    "title=[]\n",
    "picture=[]\n",
    "c_link = 0\n",
    "c_price = 0\n",
    "c_title = 0\n",
    "c_picture = 0\n",
    "# olx has 199 pages so U can chang num 31 too 200 to get all abjects (:\n",
    "# scrap only first 30 pages on website\n",
    "for a in range(1,31):\n",
    "    url=f\"https://www.olx.com.eg/vehicles/?page={a}\"\n",
    "    page=requests.get(url)\n",
    "    soup=BeautifulSoup(page.content,'html.parser')# can use \"lxml\" parser too\n",
    "    #print(soup.prettify())\n",
    "    #print('*********')\n",
    "    \n",
    "    #scrape the title then store in list then count ^__^\n",
    "    titles=soup.find_all('div',{'class':'a52608cc'}) \n",
    "    for i in range(len(titles)):\n",
    "        title.append(titles[i].a.attrs['title'])\n",
    "        c_title+=1\n",
    "    \n",
    "    \n",
    "    #scrape the line then store in list then count ^__^\n",
    "    links=soup.find_all('div',{'class':'a52608cc'})\n",
    "    for i in range(len(links)):\n",
    "        link.append(links[i].find(\"a\").attrs['href'])\n",
    "        link[i] = \"https://www.olx.com.eg/en\"+ link[i]\n",
    "        c_link+=1\n",
    "    \n",
    "    \n",
    "    #scrape the title then store in list then count ^__^\n",
    "    prices=soup.find_all('div',{'class':'_52497c97'})\n",
    "    for i in range(len(prices)) :\n",
    "        price.append(prices[i].text)\n",
    "        c_price+=1\n",
    "    \n",
    "    \n",
    "    #scrape the picture then store in list then count ^__^\n",
    "    pictures=soup.find_all('div',{'class':'ee2b0479'})\n",
    "    for i in range(len(pictures)):\n",
    "        picture.append(pictures[i].img.attrs['src'])\n",
    "        c_picture+=1   \n",
    "\n",
    "        \n",
    "    # Visualize the data that scraped ^________^  \n",
    "    for x in range(c_link):\n",
    "        print(\"name : \",title[x])\n",
    "        print(\"  \")\n",
    "        print(\"price : \",price[x])\n",
    "        print(\"  \")\n",
    "        print(\"picture link : \",picture[x])\n",
    "        print(\"  \")\n",
    "        print(\"link on website : \",link[x])\n",
    "        print(\"******************************************\")\n",
    "        print(\"******************************************\")\n",
    "        print(\"  \")\n",
    "    \n",
    "    \n",
    "'''print(\"pic = \",c_picture)\n",
    "print(\"price = \",c_price)\n",
    "print(\"link = \",c_link)\n",
    "print(\"title = \",c_title)'''"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
